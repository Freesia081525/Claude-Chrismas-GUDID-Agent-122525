import streamlit as st
import yaml
import os
from datetime import datetime
import json
from typing import Dict, List, Optional
import pandas as pd

# API clients
try:
    import openai
    from anthropic import Anthropic
    import google.generativeai as genai
except ImportError as e:
    st.error(f"Missing required library: {e}")

class AgentOrchestrator:
    """Main orchestrator for the GUDID agentic AI system"""
    
    def __init__(self, config_path: str = "agents.yaml"):
        self.config = self.load_config(config_path)
        self.agents = {}
        self.conversation_history = []
        self.initialize_agents()
    
    def load_config(self, path: str) -> Dict:
        """Load agent configurations from YAML"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return yaml.safe_load(f)
        except Exception as e:
            st.error(f"Failed to load config: {e}")
            return {}
    
    def initialize_agents(self):
        """Initialize all agents based on configuration"""
        for agent_name, agent_config in self.config.get('agents', {}).items():
            self.agents[agent_name] = Agent(agent_name, agent_config)
    
    def route_query(self, user_query: str) -> str:
        """Route user query to appropriate agent"""
        # Simple keyword-based routing (can be enhanced with ML)
        query_lower = user_query.lower()
        
        routing_keywords = {
            'nlp_analyzer': ['åˆ†æ', 'æ–‡å­—', 'analyze', 'text', 'nlp', 'å¯¦é«”'],
            'anomaly_detector': ['ç•°å¸¸', 'anomaly', 'åµæ¸¬', 'detect', 'æª¢æ¸¬'],
            'duplicate_checker': ['é‡è¤‡', 'duplicate', 'ç›¸ä¼¼', 'similar'],
            'label_matcher': ['æ¨™ç±¤', 'label', 'æ¯”å°', 'match', 'ocr'],
            'data_standardizer': ['æ¨™æº–åŒ–', 'standardize', 'æ­£è¦åŒ–', 'normalize'],
            'adverse_event_linker': ['ä¸è‰¯äº‹ä»¶', 'adverse', 'é€£çµ', 'link'],
            'recall_manager': ['å›æ”¶', 'recall', 'è¿½è¹¤', 'track'],
            'eifu_manager': ['èªªæ˜æ›¸', 'eifu', 'instructions'],
            'customs_verifier': ['æµ·é—œ', 'customs', 'æŸ¥é©—', 'verify'],
            'international_connector': ['åœ‹éš›', 'international', 'åŒæ­¥', 'sync']
        }
        
        for agent_name, keywords in routing_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                return agent_name
        
        return 'nlp_analyzer'  # Default agent
    
    def process_query(self, user_query: str, selected_agent: Optional[str] = None) -> Dict:
        """Process user query through appropriate agent"""
        agent_name = selected_agent if selected_agent else self.route_query(user_query)
        
        if agent_name not in self.agents:
            return {"error": f"Agent {agent_name} not found"}
        
        agent = self.agents[agent_name]
        response = agent.execute(user_query)
        
        # Log conversation
        self.conversation_history.append({
            'timestamp': datetime.now().isoformat(),
            'agent': agent_name,
            'query': user_query,
            'response': response
        })
        
        return {
            'agent': agent_name,
            'response': response,
            'timestamp': datetime.now().isoformat()
        }

class Agent:
    """Individual agent for specific GUDID use case"""
    
    def __init__(self, name: str, config: Dict):
        self.name = name
        self.config = config
        self.llm_provider = config.get('llm_provider', 'openai')
        self.model = config.get('model', 'gpt-4o-mini')
        self.system_prompt = config.get('system_prompt', '')
        self.capabilities = config.get('capabilities', [])
        
    def execute(self, query: str) -> str:
        """Execute agent logic based on query"""
        try:
            if self.llm_provider == 'openai':
                return self._execute_openai(query)
            elif self.llm_provider == 'anthropic':
                return self._execute_anthropic(query)
            elif self.llm_provider == 'gemini':
                return self._execute_gemini(query)
            else:
                return f"Unsupported LLM provider: {self.llm_provider}"
        except Exception as e:
            return f"Error executing agent {self.name}: {str(e)}"
    
    def _execute_openai(self, query: str) -> str:
        """Execute using OpenAI API"""
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            return "OpenAI API key not configured"
        
        client = openai.OpenAI(api_key=api_key)
        
        messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": query}
        ]
        
        response = client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0.7,
            max_tokens=2000
        )
        
        return response.choices[0].message.content
    
    def _execute_anthropic(self, query: str) -> str:
        """Execute using Anthropic API"""
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            return "Anthropic API key not configured"
        
        client = Anthropic(api_key=api_key)
        
        response = client.messages.create(
            model=self.model,
            max_tokens=2000,
            system=self.system_prompt,
            messages=[
                {"role": "user", "content": query}
            ]
        )
        
        return response.content[0].text
    
    def _execute_gemini(self, query: str) -> str:
        """Execute using Google Gemini API"""
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            return "Gemini API key not configured"
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(self.model)
        
        prompt = f"{self.system_prompt}\n\nUser Query: {query}"
        response = model.generate_content(prompt)
        
        return response.text

def main():
    st.set_page_config(
        page_title="GUDID Agentic AI System",
        page_icon="ğŸ¥",
        layout="wide"
    )
    
    # Custom CSS
    st.markdown("""
        <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: bold;
            color: #1f77b4;
            text-align: center;
            padding: 1rem 0;
        }
        .agent-card {
            background-color: #f0f2f6;
            padding: 1rem;
            border-radius: 0.5rem;
            margin: 0.5rem 0;
        }
        .metric-card {
            background-color: #e8f4f8;
            padding: 1.5rem;
            border-radius: 0.5rem;
            text-align: center;
        }
        </style>
    """, unsafe_allow_html=True)
    
    # Header
    st.markdown('<div class="main-header">ğŸ¥ GUDID æ™ºèƒ½ä»£ç†ç³»çµ±</div>', unsafe_allow_html=True)
    st.markdown("---")
    
    # Initialize orchestrator
    if 'orchestrator' not in st.session_state:
        st.session_state.orchestrator = AgentOrchestrator()
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    orchestrator = st.session_state.orchestrator
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ ç³»çµ±è¨­å®š")
        
        # API Keys Configuration
        with st.expander("ğŸ”‘ API é‡‘é‘°è¨­å®š", expanded=False):
            openai_key = st.text_input("OpenAI API Key", type="password", 
                                       value=os.getenv('OPENAI_API_KEY', ''))
            anthropic_key = st.text_input("Anthropic API Key", type="password",
                                         value=os.getenv('ANTHROPIC_API_KEY', ''))
            gemini_key = st.text_input("Gemini API Key", type="password",
                                       value=os.getenv('GEMINI_API_KEY', ''))
            
            if st.button("ğŸ’¾ å„²å­˜é‡‘é‘°"):
                os.environ['OPENAI_API_KEY'] = openai_key
                os.environ['ANTHROPIC_API_KEY'] = anthropic_key
                os.environ['GEMINI_API_KEY'] = gemini_key
                st.success("é‡‘é‘°å·²å„²å­˜ï¼")
        
        st.markdown("---")
        
        # Agent Selection
        st.subheader("ğŸ¤– é¸æ“‡ä»£ç†")
        agent_options = {
            'auto': 'ğŸ¯ è‡ªå‹•è·¯ç”±',
            'nlp_analyzer': 'ğŸ“ NLP åˆ†æ',
            'anomaly_detector': 'ğŸ” ç•°å¸¸æª¢æ¸¬',
            'duplicate_checker': 'ğŸ‘¥ é‡è¤‡æª¢æŸ¥',
            'label_matcher': 'ğŸ·ï¸ æ¨™ç±¤æ¯”å°',
            'data_standardizer': 'ğŸ“Š è³‡æ–™æ¨™æº–åŒ–',
            'adverse_event_linker': 'âš ï¸ ä¸è‰¯äº‹ä»¶é€£çµ',
            'recall_manager': 'ğŸ“¢ å›æ”¶ç®¡ç†',
            'eifu_manager': 'ğŸ“– é›»å­èªªæ˜æ›¸',
            'customs_verifier': 'ğŸ›ƒ æµ·é—œæŸ¥é©—',
            'international_connector': 'ğŸŒ åœ‹éš›é€£çµ'
        }
        
        selected_agent = st.selectbox(
            "é¸æ“‡ä»£ç†",
            options=list(agent_options.keys()),
            format_func=lambda x: agent_options[x]
        )
        
        st.markdown("---")
        
        # System Status
        st.subheader("ğŸ“Š ç³»çµ±ç‹€æ…‹")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ´»èºä»£ç†", len(orchestrator.agents))
        with col2:
            st.metric("è™•ç†è«‹æ±‚", len(st.session_state.messages))
        
        # Clear conversation
        if st.button("ğŸ—‘ï¸ æ¸…é™¤å°è©±", use_container_width=True):
            st.session_state.messages = []
            orchestrator.conversation_history = []
            st.rerun()
    
    # Main content area
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ å°è©±ä»‹é¢", "ğŸ¤– ä»£ç†è³‡è¨Š", "ğŸ“Š åˆ†æå„€è¡¨æ¿", "ğŸ“š ä½¿ç”¨èªªæ˜"])
    
    with tab1:
        # Chat interface
        st.subheader("å°è©±ä»‹é¢")
        
        # Display chat messages
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])
                if "agent" in message:
                    st.caption(f"ğŸ¤– è™•ç†ä»£ç†: {message['agent']}")
        
        # Chat input
        if prompt := st.chat_input("è«‹è¼¸å…¥æ‚¨çš„æŸ¥è©¢..."):
            # Add user message
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            
            # Process query
            with st.chat_message("assistant"):
                with st.spinner("è™•ç†ä¸­..."):
                    agent_to_use = None if selected_agent == 'auto' else selected_agent
                    result = orchestrator.process_query(prompt, agent_to_use)
                    
                    response = result.get('response', 'No response generated')
                    agent_used = result.get('agent', 'unknown')
                    
                    st.markdown(response)
                    st.caption(f"ğŸ¤– è™•ç†ä»£ç†: {agent_used}")
                    
                    # Add assistant message
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": response,
                        "agent": agent_used
                    })
    
    with tab2:
        # Agent information
        st.subheader("ä»£ç†è³‡è¨Š")
        
        for agent_name, agent in orchestrator.agents.items():
            with st.expander(f"ğŸ¤– {agent_name}", expanded=False):
                col1, col2 = st.columns([2, 1])
                
                with col1:
                    st.write("**æè¿°:**", agent.config.get('description', 'No description'))
                    st.write("**LLM æä¾›è€…:**", agent.llm_provider)
                    st.write("**æ¨¡å‹:**", agent.model)
                
                with col2:
                    st.write("**åŠŸèƒ½:**")
                    for capability in agent.capabilities:
                        st.write(f"- {capability}")
                
                with st.container():
                    st.write("**ç³»çµ±æç¤º:**")
                    st.code(agent.system_prompt, language="text")
    
    with tab3:
        # Analytics dashboard
        st.subheader("åˆ†æå„€è¡¨æ¿")
        
        if orchestrator.conversation_history:
            # Agent usage statistics
            agent_usage = {}
            for entry in orchestrator.conversation_history:
                agent = entry['agent']
                agent_usage[agent] = agent_usage.get(agent, 0) + 1
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("ç¸½è«‹æ±‚æ•¸", len(orchestrator.conversation_history))
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col2:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("æœ€å¸¸ç”¨ä»£ç†", max(agent_usage, key=agent_usage.get))
                st.markdown('</div>', unsafe_allow_html=True)
            
            with col3:
                st.markdown('<div class="metric-card">', unsafe_allow_html=True)
                st.metric("æ´»èºä»£ç†æ•¸", len(agent_usage))
                st.markdown('</div>', unsafe_allow_html=True)
            
            st.markdown("---")
            
            # Agent usage chart
            st.subheader("ä»£ç†ä½¿ç”¨çµ±è¨ˆ")
            df_usage = pd.DataFrame(list(agent_usage.items()), 
                                   columns=['Agent', 'Usage Count'])
            st.bar_chart(df_usage.set_index('Agent'))
            
            # Recent activity
            st.subheader("æœ€è¿‘æ´»å‹•")
            recent_activities = orchestrator.conversation_history[-10:]
            for activity in reversed(recent_activities):
                with st.container():
                    col1, col2 = st.columns([1, 4])
                    with col1:
                        st.write(f"**{activity['agent']}**")
                        st.caption(activity['timestamp'])
                    with col2:
                        st.write(f"Query: {activity['query'][:100]}...")
        else:
            st.info("å°šç„¡åˆ†æè³‡æ–™ã€‚è«‹é–‹å§‹ä½¿ç”¨ç³»çµ±ä»¥æŸ¥çœ‹çµ±è¨ˆè³‡è¨Šã€‚")
    
    with tab4:
        # Documentation
        st.subheader("ä½¿ç”¨èªªæ˜")
        
        st.markdown("""
        ### ğŸ“– GUDID æ™ºèƒ½ä»£ç†ç³»çµ±ä½¿ç”¨æŒ‡å—
        
        #### ğŸ¯ ç³»çµ±æ¦‚è¿°
        æœ¬ç³»çµ±æ˜¯åŸºæ–¼å…¨çƒå”¯ä¸€å™¨æè­˜åˆ¥è³‡æ–™åº«(GUDID)éœ€æ±‚çš„æ¦‚å¿µé©—è­‰(POC)ç³»çµ±ï¼Œ
        æ•´åˆäº†å¤šå€‹AIä»£ç†ä¾†è™•ç†é†«ç™‚å™¨æç®¡ç†çš„å„ç¨®ä»»å‹™ã€‚
        
        #### ğŸ¤– å¯ç”¨ä»£ç†
        
        1. **NLP åˆ†æä»£ç†** - è‡ªç„¶èªè¨€è™•ç†èˆ‡å¯¦é«”è­˜åˆ¥
        2. **ç•°å¸¸æª¢æ¸¬ä»£ç†** - è³‡æ–™ç•°å¸¸åµæ¸¬èˆ‡æ¨™è¨˜
        3. **é‡è¤‡æª¢æŸ¥ä»£ç†** - æ™ºèƒ½é‡è¤‡è³‡æ–™æª¢æ¸¬
        4. **æ¨™ç±¤æ¯”å°ä»£ç†** - æ¨™ç±¤è³‡è¨Šè‡ªå‹•æ¯”å°
        5. **è³‡æ–™æ¨™æº–åŒ–ä»£ç†** - è³‡æ–™æ¨™æº–åŒ–èˆ‡æ­£è¦åŒ–
        6. **ä¸è‰¯äº‹ä»¶é€£çµä»£ç†** - ä¸è‰¯äº‹ä»¶æ™ºèƒ½é€£çµ
        7. **å›æ”¶ç®¡ç†ä»£ç†** - ç”¢å“å›æ”¶è¿½è¹¤ç®¡ç†
        8. **é›»å­èªªæ˜æ›¸ä»£ç†** - eIFUç®¡ç†
        9. **æµ·é—œæŸ¥é©—ä»£ç†** - æµ·é—œé€²å‡ºå£æŸ¥é©—
        10. **åœ‹éš›é€£çµä»£ç†** - åœ‹éš›è³‡æ–™åº«é€£çµ
        
        #### ğŸ’¡ ä½¿ç”¨æ–¹å¼
        
        1. **é…ç½®APIé‡‘é‘°**: åœ¨å´é‚Šæ¬„çš„è¨­å®šå€åŸŸè¼¸å…¥æ‚¨çš„APIé‡‘é‘°
        2. **é¸æ“‡ä»£ç†**: é¸æ“‡ç‰¹å®šä»£ç†æˆ–ä½¿ç”¨è‡ªå‹•è·¯ç”±
        3. **è¼¸å…¥æŸ¥è©¢**: åœ¨å°è©±ä»‹é¢è¼¸å…¥æ‚¨çš„å•é¡Œæˆ–éœ€æ±‚
        4. **æŸ¥çœ‹çµæœ**: ç³»çµ±æœƒè‡ªå‹•è™•ç†ä¸¦è¿”å›çµæœ
        
        #### ğŸ“Š åŠŸèƒ½ç‰¹è‰²
        
        - âœ… å¤šLLMæ”¯æ´ (OpenAI, Anthropic, Gemini)
        - âœ… æ™ºèƒ½è·¯ç”±ç³»çµ±
        - âœ… å°è©±æ­·å²è¨˜éŒ„
        - âœ… å³æ™‚åˆ†æå„€è¡¨æ¿
        - âœ… å¯æ“´å±•çš„ä»£ç†æ¶æ§‹
        
        #### âš ï¸ æ³¨æ„äº‹é …
        
        - é€™æ˜¯æ¦‚å¿µé©—è­‰ç³»çµ±ï¼Œä¸é©ç”¨æ–¼ç”Ÿç”¢ç’°å¢ƒ
        - è«‹å‹¿è¼¸å…¥çœŸå¯¦çš„æ•æ„Ÿé†«ç™‚è³‡æ–™
        - APIé‡‘é‘°åœ¨æœƒè©±çµæŸå¾Œä¸æœƒä¿å­˜
        
        #### ğŸ”— ç›¸é—œè³‡æº
        
        - [GUDIDå®˜æ–¹ç¶²ç«™](https://example.com)
        - [æŠ€è¡“æ–‡æª”](https://example.com/docs)
        - [GitHub Repository](https://github.com/example/gudid)
        """)
        
        st.markdown("---")
        st.info("ğŸ’¡ æç¤º: ä½¿ç”¨å´é‚Šæ¬„åˆ‡æ›ä¸åŒçš„ä»£ç†ï¼Œæˆ–è®“ç³»çµ±è‡ªå‹•ç‚ºæ‚¨é¸æ“‡æœ€åˆé©çš„ä»£ç†ã€‚")

if __name__ == "__main__":
    main()
